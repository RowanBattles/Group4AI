{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Introduction\n",
    "\n",
    "This segment of the project aims to develop a machine learning model to predict clusters. The nature of the problem is a classification problem and our target variable is 'Cluster'.\n",
    "\n",
    "During our lectures, we have identified several machine learning algorithms that are particularly effective for classification problems:\n",
    "\n",
    "1. **K-Nearest Neighbors (KNN)**\n",
    "2. **Decision Trees**\n",
    "3. **Support Vector Machines (SVM)**\n",
    "\n",
    "We will begin by implementing these three algorithms with their default settings to predict the clusters. This initial step will allow us to evaluate their performance and determine the next course of action based on the outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Dataset\n",
    "\n",
    "First, we'll import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rowan\\AppData\\Local\\Temp\\ipykernel_17188\\2724300250.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# supress the warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('5dots\\dataset_with_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pauses</th>\n",
       "      <th>unique_patterns_count</th>\n",
       "      <th>total_values_count</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>empty_submissions</th>\n",
       "      <th>Box_1_Submission</th>\n",
       "      <th>Box_2_Submission</th>\n",
       "      <th>Box_3_Submission</th>\n",
       "      <th>Box_4_Submission</th>\n",
       "      <th>Box_5_Submission</th>\n",
       "      <th>...</th>\n",
       "      <th>Box_10_Timegap</th>\n",
       "      <th>Box_11_Timegap</th>\n",
       "      <th>Box_12_Timegap</th>\n",
       "      <th>Box_13_Timegap</th>\n",
       "      <th>Box_14_Timegap</th>\n",
       "      <th>Box_15_Timegap</th>\n",
       "      <th>Box_16_Timegap</th>\n",
       "      <th>Box_17_Timegap</th>\n",
       "      <th>Box_18_Timegap</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2593.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5426.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>2121.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3224.0</td>\n",
       "      <td>3961.0</td>\n",
       "      <td>5433.0</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>3552.0</td>\n",
       "      <td>6360.0</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>2816.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4282.0</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>4399.0</td>\n",
       "      <td>3808.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pauses  unique_patterns_count  total_values_count  duplicates  \\\n",
       "0       1                    4.0                 5.0         1.0   \n",
       "1       6                   25.0                26.0         1.0   \n",
       "2       1                   35.0                45.0         9.0   \n",
       "3       2                   51.0                58.0         5.0   \n",
       "4       1                   45.0                58.0        12.0   \n",
       "\n",
       "   empty_submissions  Box_1_Submission  Box_2_Submission  Box_3_Submission  \\\n",
       "0                0.0               3.0               2.0               0.0   \n",
       "1                0.0               0.0               1.0               1.0   \n",
       "2                1.0               3.0               3.0               3.0   \n",
       "3                2.0               5.0               3.0               3.0   \n",
       "4                1.0               3.0               6.0               4.0   \n",
       "\n",
       "   Box_4_Submission  Box_5_Submission  ...  Box_10_Timegap  Box_11_Timegap  \\\n",
       "0               0.0               0.0  ...         10000.0         10000.0   \n",
       "1               1.0               0.0  ...          2593.0         10000.0   \n",
       "2               3.0               2.0  ...          4760.0          4392.0   \n",
       "3               3.0               3.0  ...          3344.0          2352.0   \n",
       "4               2.0               3.0  ...          4282.0          3193.0   \n",
       "\n",
       "   Box_12_Timegap  Box_13_Timegap  Box_14_Timegap  Box_15_Timegap  \\\n",
       "0         10000.0         10000.0         10000.0         10000.0   \n",
       "1          3092.0          4389.0         10000.0          5426.0   \n",
       "2          4784.0          2121.0          4000.0          3224.0   \n",
       "3          2464.0          3552.0          6360.0          3064.0   \n",
       "4          3551.0          3664.0          3056.0          4399.0   \n",
       "\n",
       "   Box_16_Timegap  Box_17_Timegap  Box_18_Timegap  Cluster  \n",
       "0         10000.0         10000.0         10000.0        1  \n",
       "1         10000.0         10000.0         10000.0        3  \n",
       "2          3961.0          5433.0          2176.0        0  \n",
       "3          2816.0          3664.0          2504.0        0  \n",
       "4          3808.0         10000.0         10000.0        0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🛠️ Preprocessing\n",
    "\n",
    "**Objective**: To establish a baseline performance and understand the potential of various models using all available features initially. This will help in assessing the initial predictive capability of the models on the dataset created from students' submission time boxes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Target variable\n",
    "\n",
    "The target variable is the variable we are trying to predict. There are four clusters, which are numbers from 0 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 🛠️ Features\n",
    "\n",
    "Given the fact the clusters were created by using all time boxes from the student's submissions, we will use all features initially to train the models. Therefore, all columns except the column 'Cluster' will be used initially as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Cluster', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🪓 Splitting into Train/Test\n",
    "\n",
    "To ensure a fair comparison between different models, we will use the same train and test sets for all three models. This process will be done only once to maintain consistency across model evaluations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚖️ Scaling\n",
    "The K-Nearest Neighbors (KNN) algorithm and Support Vector Machines (SVM) both rely on distance calculations to make predictions. For instance, KNN uses the concept of \"being near\" to decide cluster membership for new data points. This \"being near\" is calculated using [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance), which measures absolute differences between values of the same feature, but not among different features.\n",
    "\n",
    "Therefore, it is necessary to scale all features to ensure they use the same unit of measurement. Without scaling, features with larger ranges can disproportionately influence the distance calculations, leading to biased results. A common approach is to use [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) as the unit, transforming all features to have a mean of 0 and a standard deviation of 1. This transformation is achieved using the `StandardScaler` from sklearn.\n",
    "\n",
    "Example:\n",
    "> Given the numbers 6 and 8, the Euclidean distance is 2. Given the numbers 95 and 100, the Euclidean distance is 5. However, 95 and 100 are closer to each other (95%) than 6 and 8 are (75%). Scaling ensures that all features contribute equally to the distance calculations.\n",
    "\n",
    "[Decision Trees, however, do not require feature scaling because they are not distance-based algorithms. Instead, they work by splitting the data based on feature values, making decisions based on thresholds. As a result, the relative scales of the features do not affect their performance](https://towardsdatascience.com/do-decision-trees-need-feature-scaling-97809eaa60c6) \n",
    "\n",
    "**Therefore, we will scale the features and use them only for SVM and kNN models.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧬 Modelling: k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier() # kNN model parameters are set to default: n_neighbors=5, weights='uniform'\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧬 Modelling: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC() # Support Vector Machine parameters are set to default: with kernel='rbf', C=1.0, gamma='scale'\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧬 Modelling: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier() # Decision Tree parameters are set to default: with criterion='gini', splitter='best'\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔬 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.847682119205298\n",
      "Decision Tree Accuracy: 0.7671081677704195\n",
      "SVM Accuracy: 0.9635761589403974\n"
     ]
    }
   ],
   "source": [
    "print(f\"KNN Accuracy: {accuracy_knn}\")\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt}\")\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Conclusion:**_\n",
    "\n",
    "SVM achieved the highest accuracy (96.36%), outperforming KNN (84.77%) and Decision Tree (77.37%). The next course of actions include detailed classification report, confusion matrix and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84       153\n",
      "           1       0.85      0.86      0.85       162\n",
      "           2       0.82      0.92      0.87       336\n",
      "           3       0.86      0.78      0.81       255\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.86      0.84      0.85       906\n",
      "weighted avg       0.85      0.85      0.85       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78       153\n",
      "           1       0.85      0.70      0.77       162\n",
      "           2       0.81      0.73      0.77       336\n",
      "           3       0.70      0.83      0.76       255\n",
      "\n",
      "    accuracy                           0.77       906\n",
      "   macro avg       0.78      0.77      0.77       906\n",
      "weighted avg       0.77      0.77      0.77       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.97      0.89      0.93       162\n",
      "           2       0.98      0.98      0.98       336\n",
      "           3       0.92      0.98      0.95       255\n",
      "\n",
      "    accuracy                           0.96       906\n",
      "   macro avg       0.97      0.96      0.96       906\n",
      "weighted avg       0.96      0.96      0.96       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Conclusion:**_\n",
    "\n",
    "- The recall for cluster 1 in SVM (89%) is lower than the rest of the clusters, which is still slightly higher than kNN (86%) and significantly higher than Decision Trees (73%).\n",
    "\n",
    "- From the classification report alone, it can be concluded that SVM outperforms all other models in terms of precision (ranging from 92% to 99%) and recall (ranging from 89% to 98%). The second-best model is kNN, with precision ranging from 82% to 90% and recalls ranging from 78% to 92%. The worst-performing model is Decision Trees, with precision values ranging from 69% to 85% and recall values ranging from 69% to 84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix:\n",
      "[[121   0  32   0]\n",
      " [  0 139   2  21]\n",
      " [ 13   1 310  12]\n",
      " [  0  24  33 198]]\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Summary:**_\n",
    "\n",
    "- For Cluster '0', the KNN model correctly identified 121 instances, but misclassified 32 instances as Cluster '2'.\n",
    "\n",
    "- In Cluster '1', the KNN model accurately identified 139 instances as '1', but erroneously classified 2 instances as '2' and 21 instances as '12'.\n",
    "\n",
    "- Regarding Cluster '2', the KNN model correctly identified 310 instances as '2', but mistakenly classified 13 instances as '0', 1 instance as '1', and 12 instances as '3'.\n",
    "\n",
    "- In Cluster '3', the KNN model accurately identified 198 instances as '3', but misclassified 24 instances as '1' and 33 instances as '2'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Confusion Matrix:\n",
      "[[124   0  28   1]\n",
      " [  0 113   5  44]\n",
      " [ 42   3 246  45]\n",
      " [  1  17  25 212]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Summary:**_\n",
    "\n",
    "- For Cluster '0', the Decision Tree model correctly identified 125 instances, but misclassified 27 instances as Cluster '2' and 1 instance as Cluster '3'.\n",
    "\n",
    "- In Cluster '1', the Decision Tree model accurately identified 118 instances as '1', but erroneously classified 5 instances as '2' and 39 instances as '12'.\n",
    "\n",
    "- Regarding Cluster '2', the Decision Tree model correctly identified 233 instances as '2', but mistakenly classified 45 instances as '0', 3 instances as '1', and 55 instances as '3'.\n",
    "\n",
    "- In Cluster '3', the Decision Tree model accurately identified 215 instances as '3', but misclassified 18 instances as '1' and 22 instances as '2'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix:\n",
      "[[149   0   4   0]\n",
      " [  0 144   1  17]\n",
      " [  1   1 330   4]\n",
      " [  0   3   2 250]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Summary:**_\n",
    "\n",
    "- For Cluster '0', the SVM model correctly identified 149 instances, with no misclassifications.\n",
    "\n",
    "- In Cluster '1', the SVM model accurately identified 144 instances as '1', but misclassified 1 instance as '2' and 17 instances as '12'.\n",
    "\n",
    "- Regarding Cluster '2', the SVM model correctly identified 330 instances as '2', but mistakenly classified 1 instance as '0', 1 instance as '1', and 4 instances as '3'.\n",
    "\n",
    "- In Cluster '3', the SVM model accurately identified 250 instances as '3', but misclassified 3 instances as '1' and 2 instances as '2'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Conclusion from Confusion Matrices:**_\n",
    "\n",
    "- SVM demonstrates the highest accuracy and maintains consistency across all clusters in comparison with other models.\n",
    "- Cluster '0' tends to be mistaken as '2' across all models.\n",
    "- Cluster '2' appears more challenging, as it was mistaken with all other clusters in all three of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔎 Evaluating Overfitting, Underfitting, and Generalization\n",
    "\n",
    "To assess our models for overfitting, underfitting, and generalization, we'll employ two steps:\n",
    "\n",
    "- **Initial Evaluation**: \n",
    "We'll begin by comparing the classification reports obtained from both the test and train sets. This initial examination will provide insights into any inconsistencies between the model's performance on seen versus unseen data.\n",
    "\n",
    "- **Cross-Validation Analysis**:\n",
    "Utilizing the k-fold cross-validation technique, we'll conduct a series of evaluations, training the models on various subsets of the data and assessing their performance on unseen partitions. This method ensures a robust estimation of model performance and helps reveal potential overfitting or underfitting tendencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Intial Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on training data: 0.998068\n",
      "SVM Accuracy on test data: 0.963576\n",
      "Training classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       513\n",
      "           2       1.00      1.00      1.00      1329\n",
      "           3       1.00      1.00      1.00      1058\n",
      "\n",
      "    accuracy                           1.00      3623\n",
      "   macro avg       1.00      1.00      1.00      3623\n",
      "weighted avg       1.00      1.00      1.00      3623\n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       153\n",
      "           1       0.97      0.89      0.93       162\n",
      "           2       0.98      0.98      0.98       336\n",
      "           3       0.92      0.98      0.95       255\n",
      "\n",
      "    accuracy                           0.96       906\n",
      "   macro avg       0.97      0.96      0.96       906\n",
      "weighted avg       0.96      0.96      0.96       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = svm.predict(X_train_scaled)\n",
    "a_accuracy = accuracy_score(y_train, a)\n",
    "print(f\"SVM Accuracy on training data: {a_accuracy:.6f}\")\n",
    "b = svm.predict(X_test_scaled)\n",
    "b_accuracy = accuracy_score(y_test, b)\n",
    "print(f\"SVM Accuracy on test data: {b_accuracy:.6f}\")\n",
    "\n",
    "print(\"Training classification report:\\n\", classification_report(y_train, a))\n",
    "print(\"Test classification report:\\n\", classification_report(y_test, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy on training data: 0.911123\n",
      "KNN Accuracy on test data: 0.847682\n",
      "Training classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92       723\n",
      "           1       0.91      0.96      0.94       513\n",
      "           2       0.86      0.96      0.91      1329\n",
      "           3       0.94      0.85      0.89      1058\n",
      "\n",
      "    accuracy                           0.91      3623\n",
      "   macro avg       0.92      0.91      0.92      3623\n",
      "weighted avg       0.92      0.91      0.91      3623\n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84       153\n",
      "           1       0.85      0.86      0.85       162\n",
      "           2       0.82      0.92      0.87       336\n",
      "           3       0.86      0.78      0.81       255\n",
      "\n",
      "    accuracy                           0.85       906\n",
      "   macro avg       0.86      0.84      0.85       906\n",
      "weighted avg       0.85      0.85      0.85       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = knn.predict(X_train_scaled)\n",
    "a_accuracy = accuracy_score(y_train, a)\n",
    "print(f\"KNN Accuracy on training data: {a_accuracy:.6f}\")\n",
    "b = knn.predict(X_test_scaled)\n",
    "b_accuracy = accuracy_score(y_test, b)\n",
    "print(f\"KNN Accuracy on test data: {b_accuracy:.6f}\")\n",
    "\n",
    "print(\"Training classification report:\\n\", classification_report(y_train, a))\n",
    "print(\"Test classification report:\\n\", classification_report(y_test, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Accuracy on training data: 1.000000\n",
      "Decision Trees Accuracy on test data: 0.767108\n",
      "Training classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       513\n",
      "           2       1.00      1.00      1.00      1329\n",
      "           3       1.00      1.00      1.00      1058\n",
      "\n",
      "    accuracy                           1.00      3623\n",
      "   macro avg       1.00      1.00      1.00      3623\n",
      "weighted avg       1.00      1.00      1.00      3623\n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78       153\n",
      "           1       0.85      0.70      0.77       162\n",
      "           2       0.81      0.73      0.77       336\n",
      "           3       0.70      0.83      0.76       255\n",
      "\n",
      "    accuracy                           0.77       906\n",
      "   macro avg       0.78      0.77      0.77       906\n",
      "weighted avg       0.77      0.77      0.77       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = dt.predict(X_train)\n",
    "a_accuracy = accuracy_score(y_train, a)\n",
    "print(f\"Decision Trees Accuracy on training data: {a_accuracy:.6f}\")\n",
    "b = dt.predict(X_test)\n",
    "b_accuracy = accuracy_score(y_test, b)\n",
    "print(f\"Decision Trees Accuracy on test data: {b_accuracy:.6f}\")\n",
    "\n",
    "print(\"Training classification report:\\n\", classification_report(y_train, a))\n",
    "print(\"Test classification report:\\n\", classification_report(y_test, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Conclusion**_\n",
    "KNN exhibits decent performance but shows signs of overfitting, while Decision Trees suffer from significant overfitting, which leads to poor performance on unseen data. Although both SVM and Decision Trees achieve perfect accuracy on the training data, there is a noticeable decline in performance on the test set, particularly for Decision Trees, suggesting a lack of generalization. Therefore, we can conclude the SVM model outperforms both KNN and Decision Trees in terms of accuracy and generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the training speed, we will use intel extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since kNN and SVM require scaling we will perform it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Cross Validation for kNN:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Cross Validation Scores: [0.84216336 0.84657837 0.85209713 0.86423841 0.86298343]\n",
      "kNN Cross Validation Mean Score: 0.8536121376215042\n",
      "kNN Cross Validation Standard Deviation: 0.008758795701430844\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(knn, X_Scaled, y, cv=5)\n",
    "print(f\"kNN Cross Validation Scores: {scores}\")\n",
    "print(f\"kNN Cross Validation Mean Score: {np.mean(scores)}\")\n",
    "print(f\"kNN Cross Validation Standard Deviation: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Cross Validation for SVM:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Cross Validation Scores: [0.94591611 0.96357616 0.95916115 0.97461369 0.96022099]\n",
      "SVM Cross Validation Mean Score: 0.9606976205285817\n",
      "SVM Cross Validation Standard Deviation: 0.00919808359254364\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm, X_Scaled, y, cv=5)\n",
    "print(f\"SVM Cross Validation Scores: {scores}\")\n",
    "print(f\"SVM Cross Validation Mean Score: {np.mean(scores)}\")\n",
    "print(f\"SVM Cross Validation Standard Deviation: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Cross Validation for Decision Trees:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Cross Validation Scores: [0.74282561 0.76931567 0.76490066 0.79028698 0.78121547]\n",
      "Decision Trees Cross Validation Mean Score: 0.7697088775871112\n",
      "Decision Trees Cross Validation Standard Deviation: 0.016135944726401903\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt, X, y, cv=5)\n",
    "print(f\"Decision Trees Cross Validation Scores: {scores}\")\n",
    "print(f\"Decision Trees Cross Validation Mean Score: {np.mean(scores)}\")\n",
    "print(f\"Decision Trees Cross Validation Standard Deviation: {np.std(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Conclusion**_\n",
    "> Based on the results from Cross Validation, SVM still outperforms other models with the highest mean score (accuracy). When it comes to standard deviation, SVM has the highest variances across different train and test set splits. However, the number is still considerably low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   2.1s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.7s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.9s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.7s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   1.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   3.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   1.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.9s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.8s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   1.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.9s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.9s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   1.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   1.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.9s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.9s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   2.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.7s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.7s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.6s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.4s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.3s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.4s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.4s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.6s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.5s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.4s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.8s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   2.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   1.8s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   1.6s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.5s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.3s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.6s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.6s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "SVC(C=100, gamma=0.001, kernel='sigmoid')\n",
      "0.9768211920529801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       153\n",
      "           1       0.99      0.96      0.97       162\n",
      "           2       0.98      0.98      0.98       336\n",
      "           3       0.97      0.98      0.97       255\n",
      "\n",
      "    accuracy                           0.98       906\n",
      "   macro avg       0.98      0.98      0.98       906\n",
      "weighted avg       0.98      0.98      0.98       906\n",
      "\n",
      "[[151   0   2   0]\n",
      " [  0 155   1   6]\n",
      " [  3   0 330   3]\n",
      " [  0   2   4 249]]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_predictions = grid.predict(X_test_scaled)\n",
    "print(accuracy_score(y_test, grid_predictions))\n",
    "print(classification_report(y_test, grid_predictions))\n",
    "print(confusion_matrix(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _**Next Course of Action**_\n",
    "\n",
    "Based on the conclusion we have made, it is clear Support Vector Machine is more suitable for this dataset. In the next part, we will reduce the features and aim to improve prediction on cluster '0' and cluster '2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9591611479028698\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       153\n",
      "           1       0.97      0.90      0.94       162\n",
      "           2       0.98      0.97      0.97       336\n",
      "           3       0.92      0.97      0.95       255\n",
      "\n",
      "    accuracy                           0.96       906\n",
      "   macro avg       0.96      0.96      0.96       906\n",
      "weighted avg       0.96      0.96      0.96       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train svm using best parameters\n",
    "svm = SVC(C=10, gamma=0.01, kernel='rbf')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export the svm model\n",
    "import joblib\n",
    "joblib.dump(svm, 'svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pauses</th>\n",
       "      <th>unique_patterns_count</th>\n",
       "      <th>total_values_count</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>empty_submissions</th>\n",
       "      <th>Box_1_Submission</th>\n",
       "      <th>Box_2_Submission</th>\n",
       "      <th>Box_3_Submission</th>\n",
       "      <th>Box_4_Submission</th>\n",
       "      <th>Box_5_Submission</th>\n",
       "      <th>...</th>\n",
       "      <th>Box_9_Timegap</th>\n",
       "      <th>Box_10_Timegap</th>\n",
       "      <th>Box_11_Timegap</th>\n",
       "      <th>Box_12_Timegap</th>\n",
       "      <th>Box_13_Timegap</th>\n",
       "      <th>Box_14_Timegap</th>\n",
       "      <th>Box_15_Timegap</th>\n",
       "      <th>Box_16_Timegap</th>\n",
       "      <th>Box_17_Timegap</th>\n",
       "      <th>Box_18_Timegap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pauses  unique_patterns_count  total_values_count  duplicates  \\\n",
       "0     7.0                   16.0                16.0         0.0   \n",
       "\n",
       "   empty_submissions  Box_1_Submission  Box_2_Submission  Box_3_Submission  \\\n",
       "0                0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Box_4_Submission  Box_5_Submission  ...  Box_9_Timegap  Box_10_Timegap  \\\n",
       "0               1.0               2.0  ...        10000.0         10000.0   \n",
       "\n",
       "   Box_11_Timegap  Box_12_Timegap  Box_13_Timegap  Box_14_Timegap  \\\n",
       "0         10000.0         10000.0         10000.0         10000.0   \n",
       "\n",
       "   Box_15_Timegap  Box_16_Timegap  Box_17_Timegap  Box_18_Timegap  \n",
       "0         10000.0         10000.0         10000.0         10000.0  \n",
       "\n",
       "[1 rows x 95 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv\n",
    "test = pd.read_csv('./Demo/5 dot test/bin/Debug/test.csv')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Predict for test\n",
    "predictions = svm.predict(test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
